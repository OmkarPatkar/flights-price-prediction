{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this Notebook we will be building a model to predict Flight Price. In doing so, we would be going through the life cycle of a data science project. Data is given from Kaggle.\n\nHere's the link to the dataset: https://www.kaggle.com/nikhilmittal/flight-fare-prediction-mh\n\n\nSo, Let's begin...\n\n1. Import Libraries\n2. Load Train Data\n3. Basic EDA\n4. Data_Cleaning & Feature Extraction\n5. Handling Categorical Data\n    * Airline\n    * Source & Destination\n    * Route & Additional_Info\n    * Total_Stops\n6. Load Test data\n7. Preprocessing\n8. Feature Selection\n9. Feature Importance using ExtraTreeRegressor\n10. Model Building\n    * RandomForestRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"#to work with excelfile run below command\n!pip install openpyxl","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Train Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_excel(r'../input/flight-fare-prediction-mh/Data_Train.xlsx')\n# to see maximum data values\npd.set_option('display.max_columns', None)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get insights from data\ntrain_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see that our data has many independent features of object type and one dependent feature i.e. Price of integer type ,which we will be predicting.\n\nWe need to convert the data to numeric values to build the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.Duration.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's have a look at the shape of our data\ntrain_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop na values\ntrain_data.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the shape again\ntrain_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there is just one na value"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see if there are any null values\ntrain_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"We will be converting the data, so it will be suitable to build the model.\nConvert the object date to datetime. and separate it intodaya and month."},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime as dt\ntrain_data['Journey_day'] = pd.to_datetime(train_data.Date_of_Journey, format='%d/%m/%Y').dt.day\ntrain_data['Journey_month'] = pd.to_datetime(train_data.Date_of_Journey, format='%d/%m/%Y').dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now drop the column\ntrain_data.drop(['Date_of_Journey'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert and extract hour, minute from departure time, then drop the column\ntrain_data['Dep_hour'] = pd.to_datetime(train_data.Dep_Time).dt.hour\ntrain_data['Dep_minute'] = pd.to_datetime(train_data.Dep_Time).dt.minute\ntrain_data.drop(['Dep_Time'], axis = 1, inplace = True)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert and extract hour, minute from arrival time, then drop the column\ntrain_data['Arrival_hour'] = pd.to_datetime(train_data.Arrival_Time).dt.hour\ntrain_data['Arrival_minute'] = pd.to_datetime(train_data.Arrival_Time).dt.minute\ntrain_data.drop(['Arrival_Time'], axis = 1, inplace = True)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Time taken by plane to reach destination is called Duration\n# It is the differnce betwwen Departure Time and Arrival time\n\n# Assigning and converting Duration column into list\nduration = list(train_data[\"Duration\"])\n\nfor i in range(len(duration)):\n    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n        if \"h\" in duration[i]:\n            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n        else:\n            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n\nduration_hours = []\nduration_mins = []\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create new columns and store the values\ntrain_data['Duration_hours'] = duration_hours\ntrain_data['Duration_mins'] = duration_mins","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop the column\ntrain_data.drop(['Duration'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handling Categorical Values"},{"metadata":{},"cell_type":"markdown","source":"We will be converting reamaning objects to numeric values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.Airline.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's visualize the price of all airlines\nsns.catplot(y = 'Price', x = 'Airline', data = train_data.sort_values('Price', ascending = False), kind = 'boxen', height = 6, aspect = 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see jet airways has high prices, rest are quiet similar in price"},{"metadata":{},"cell_type":"markdown","source":"As Airline, Source, Destination are  Nominal Categorical data we will perform OneHotEncoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"Airline = train_data[[\"Airline\"]]\n\nAirline = pd.get_dummies(Airline, drop_first= True)\n\nAirline.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Source'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize the prices at the source \nsns.catplot(y = 'Price', x = 'Source', data = train_data.sort_values('Price', ascending = False), kind = 'boxen', height = 4, aspect = 3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Source = train_data[['Source']]\nSource = pd.get_dummies(Source, drop_first = True)\nSource.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Destination'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Destination = train_data[['Destination']]\nDestination = pd.get_dummies(Destination, drop_first = True)\nDestination.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Route']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Additional_Info contains almost 80% no_info\n# Route and Total_Stops are related to each other\n\ntrain_data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Total_Stops'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As this is case of Ordinal Categorical type we perform LabelEncoder\n# Here Values are assigned with corresponding keys\n\ntrain_data.replace({'non-stop': 0, '1 stop': 1, '2 stops': 2, '3 stops': 3, '4 stops': 4}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combine all data\ndata_train = pd.concat([train_data, Airline, Source, Destination], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.drop(['Airline','Source', 'Destination'], axis = 1, inplace = True)\ndata_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Test Data"},{"metadata":{},"cell_type":"markdown","source":"Load the test data and perform all the preprocessing steps we did for train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_excel(r'../input/flight-fare-prediction-mh/Test_set.xlsx')\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test data info:')\nprint('_' * 80)\nprint(test_data.info())\n\nprint('\\n \\n Null values:')\nprint('_' * 80)\ntest_data.dropna(inplace = True)\nprint(test_data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA of Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Date_of_Journey\ntest_data['Journey_day'] = pd.to_datetime(test_data.Date_of_Journey,format = '%d/%m/%Y').dt.day\ntest_data['Journey_month'] = pd.to_datetime(test_data.Date_of_Journey, format = '%d/%m/%Y').dt.month\ntest_data.drop(['Date_of_Journey'], axis = 1,inplace = True)\n\n# Dep_Time\ntest_data[\"Dep_hour\"] = pd.to_datetime(test_data[\"Dep_Time\"]).dt.hour\ntest_data[\"Dep_min\"] = pd.to_datetime(test_data[\"Dep_Time\"]).dt.minute\ntest_data.drop([\"Dep_Time\"], axis = 1, inplace = True)\n\n# Arrival_Time\ntest_data[\"Arrival_hour\"] = pd.to_datetime(test_data.Arrival_Time).dt.hour\ntest_data[\"Arrival_min\"] = pd.to_datetime(test_data.Arrival_Time).dt.minute\ntest_data.drop([\"Arrival_Time\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Duration\nDuration = list(test_data['Duration'])\n\nfor i in range(len(Duration)):\n    if len(Duration[i].split()) != 2:\n        if 'h' in Duration[i]:\n            Duration[i] = Duration[i].strip() + ' 0m'\n        else:\n            Duration[i] = '0h ' + Duration[i]\n        \nDuration_hour = []\nDuration_mins = []\nfor i in range(len(Duration)):\n    Duration_hour.append(int(Duration[i].split(sep = 'h')[0]))\n    Duration_mins.append(int(Duration[i].split(sep = 'm')[0].split()[-1]))\n\ntest_data['Duration_hours'] = Duration_hour\ntest_data['Duration_minutes'] = Duration_mins\ntest_data.drop(['Duration'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical data\n\nprint(\"Airline\")\nprint(\"-\"*75)\nprint(test_data[\"Airline\"].value_counts())\nAirline = pd.get_dummies(test_data[\"Airline\"], drop_first= True)\n\nprint()\n\nprint(\"Source\")\nprint(\"-\"*75)\nprint(test_data[\"Source\"].value_counts())\nSource = pd.get_dummies(test_data[\"Source\"], drop_first= True)\n\nprint()\n\nprint(\"Destination\")\nprint(\"-\"*75)\nprint(test_data[\"Destination\"].value_counts())\nDestination = pd.get_dummies(test_data[\"Destination\"], drop_first = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Additional_Info contains almost 80% no_info\n# Route and Total_Stops are related to each other\ntest_data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing Total_Stops\ntest_data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Combine all data:  test_data + Airline + Source + Destination\ndata_test = pd.concat([test_data, Airline, Source, Destination], axis = 1)\n\ndata_test.drop([\"Airline\", \"Source\", \"Destination\"], axis = 1, inplace = True)\n\nprint(\"Shape of test data : \", data_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection\n\nFinding out the best feature which will contribute and have good relation with target variable. Following are some of the feature selection methods,\n\n**heatmap**\n\n**feature_importance_**\n\n**SelectKBest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Separate independent and dependent data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Independent data\nx = data_train.drop(['Price'], axis = 1)\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dependent data\ny = data_train['Price']\ny.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finds correlation between Independent and dependent attributes\n\nplt.figure(figsize = (18,18))\nsns.heatmap(data_train.corr(), annot = True, cmap = 'Blues')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Important feature using ExtraTreesRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\n\nmodel = ExtraTreesRegressor()\nmodel.fit(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot graph of feature importances for better visualization\n\nplt.figure(figsize = (10, 10))\nfeat_imp = pd.Series(model.feature_importances_, index = x.columns)\nfeat_imp.nlargest(20).plot(kind = 'barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fitting model using Random Forest\n"},{"metadata":{},"cell_type":"markdown","source":"Split the data using train_test_split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create model and fit the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nreg_rf = RandomForestRegressor()\nreg_rf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict on x_test data "},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = reg_rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the score"},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_rf.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_rf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the error difference "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(y_test-y_pred)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test, y_pred, alpha = 0.5)\nplt.xlabel(\"y_test\")\nplt.ylabel(\"y_pred\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the MAE, MSE, and RSME score"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, y_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.r2_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter Tuning\n\n* Choose following method for hyperparameter tuning\n    * RandomizedSearchCV --> Fast\n    * GridSearchCV\n* Assign hyperparameters in form of dictionery\n* Fit the model\n* Check best paramters and best score"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Randomized Search CV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 10, stop = 1200, num = 12 )]\n\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num= 6)]\n\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create random grid\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random search of parameters, using 5 fold cross validation, \n# search across 100 different combinations\nrf_random = RandomizedSearchCV(estimator = reg_rf, param_distributions = random_grid, scoring = 'neg_mean_squared_error',n_iter = 10, cv = 5, verbose = 2, random_state = 42, n_jobs = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find the best params"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the predictions on test data "},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = rf_random.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the error difference"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8,8))\nsns.distplot(y_test-predictions)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8,8))\nplt.scatter(y_test, predictions, alpha = 0.5)\nplt.xlabel('y_test')\nplt.ylabel('y_pred')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the MAE, MSE, and RSME score"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('MAE:', metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save the model to reuse it again"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n# open a file, where you ant to store the data\nfile = open('flight_rf.pkl', 'wb')\n\n# dump information to that file\npickle.dump(rf_random, file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flight_model = open('flight_rf.pkl','rb')\nforest = pickle.load(flight_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction = forest.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.r2_score(y_test, y_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" !pip freeze > '../working/flight_requirements.txt'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}